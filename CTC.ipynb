{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CTC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namanh218/vietnamese_rec/blob/master/CTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIfCdUZjMGJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHdSQI5-YUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1.0rc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpqxYEtz97u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import library\n",
        "import shutil\n",
        "import pathlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow #only in Colab because using cv2.imshow is not allowed in Colab\n",
        "import os\n",
        "import mahotas\n",
        "import imutils\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAdSKxFMCM63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Check version Tensorflow\n",
        " print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0byj2rs-LPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Access to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6QVoMTLtTRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All path to access\n",
        "img_train_path = './drive/My Drive/0916_Data Samples 2'\n",
        "img_test_path = './drive/My Drive/1015_Private Test'\n",
        "img_test_folder = pathlib.Path(img_test_path)\n",
        "img_folder = pathlib.Path(img_train_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF_ET3pKl0Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Path to json file\n",
        "json_name = 'labels.json'\n",
        "path = os.path.join(img_train_path, json_name)\n",
        "labels = json.loads(open(path).read())\n",
        "test_path_2 = os.path.join(img_test_path, json_name)\n",
        "test_labels = json.loads(open(test_path_2).read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqyIQNJxjoCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Func to get path\n",
        "def sep_json(list_, dict_, path_):\n",
        "  for key, value in dict_.items():\n",
        "    path = os.path.join(path_, key)\n",
        "    list_.append(path)\n",
        "  return list_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7LwgYdYqMuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get all path from train images\n",
        "all_train_path = []\n",
        "sep_json(all_train_path, labels, img_train_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RdzSm2okEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get all path from test images\n",
        "all_test_path = []\n",
        "sep_json(all_test_path, test_labels, img_test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NksEbThCk4DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Delete json link\n",
        "def delete_json(list_, path_):\n",
        "  for i in range(len(list_)):\n",
        "    if path_.strip('.').lstrip('/') + '/labels.json' == list_[i]:\n",
        "      print(i)\n",
        "      list_.pop(i)\n",
        "\n",
        "delete_json(all_train_path, img_train_path)\n",
        "delete_json(all_test_path, img_test_path)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRZiswK5l7nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All the letter and function to pad sequences letters\n",
        "letters = \" #'()+,-./:0123456789ABCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnopqrstuwvxyzÂÊÔàáâãèẹéêìíòóôõùúýăĐđĩũƠơưạảấầẫẩậắằẵặẻẽếềểễệỉịọỏốồổỗộớờởỡợụủỨứừửữựỳỵỷỹ\"\n",
        "number_letters = len(letters)\n",
        "print(number_letters)\n",
        "def text_to_labels(text):\n",
        "  for c in text:\n",
        "    if letters.find(c) == -1:\n",
        "      print(c)\n",
        "  return list(map(lambda x: letters.index(x), text))\n",
        "\n",
        "def label_to_text(labels):\n",
        "    return ''.join(list(map(lambda x: letters[x] if x < len(letters) else \"\", labels)))\n",
        "\n",
        "def map_letters(list_key, list_value, map_, dict_):\n",
        "  for key, value in dict_.items():\n",
        "    list_key.append(key)\n",
        "    list_value.append(value)\n",
        "    label = text_to_labels(value)\n",
        "    label = pad_sequences([label], maxlen = 70, padding ='post')\n",
        "    map_.append(label)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HQBFUVMxnV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Map for the train\n",
        "train_key = []\n",
        "train_values = []\n",
        "train_labels_map = []\n",
        "map_letters(train_key, train_values, train_labels_map, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOc6HlY5pw7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Map for the test\n",
        "test_key = []\n",
        "test_values = []\n",
        "test_labels_map = []\n",
        "map_letters(test_key, test_values, test_labels_map, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64BZYyNy75dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocess data\n",
        "def load_and_preprocess_from_path_label(path, label):\n",
        "  return preprocess_path(path), label\n",
        "def preprocess_path(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=1)\n",
        "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, [2048, 128])\n",
        "    image /= 255.\n",
        "    # image = (image*2) - 1  # normalize to [-1,1] range\n",
        "    # image = tf.image.per_image_standardization(image)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kde9YwgWb_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare for dataset\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_SAMPLES = 1823\n",
        "TEST_SAMPLES = 549\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=100, augment=False):\n",
        "    # This is a small dataset, only load it once, and keep it in memory.\n",
        "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "    # fit in memory.\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "    # Repeat forever\n",
        "    ds = ds.repeat()\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    \n",
        "    # if augment:\n",
        "    #     ds.map(augmentation, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "    # is training.\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPGWB-6y3BXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create new dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((all_train_path, train_labels_map))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((all_test_path, test_labels_map))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNUpluOmWhrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare for train set\n",
        "train_ds = train_ds.map(load_and_preprocess_from_path_label, num_parallel_calls=AUTOTUNE)\n",
        "train_ds = prepare_for_training(train_ds, shuffle_buffer_size=TRAIN_SAMPLES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW0oRxd53XBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare for test set\n",
        "test_ds = test_ds.map(load_and_preprocess_from_path_label, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = prepare_for_training(test_ds, cache=False, shuffle_buffer_size=TEST_SAMPLES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJR5_sDOCq-y",
        "colab_type": "code",
        "outputId": "bafc6616-8181-420e-a90d-c695dd6d5864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Import our model, different layers and activation function \n",
        "from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, sigmoid, softmax, selu, tanh\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-DZ3RrrZrmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model CRNN and BLSTM\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Multiply, Activation\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Tensorflow Keras layer implementation of the gated convolution.\n",
        "    Args:\n",
        "        kwargs: Conv2D keyword arguments.\n",
        "    Reference:\n",
        "        T. Bluche, R. Messina,\n",
        "        Gated convolutional recurrent neural networks for multilingual handwriting recognition.\n",
        "        14th IAPR International Conference on Document Analysis andRecognition (ICDAR),\n",
        "        p. 646–651, 11 2017.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class GatedConv2D(Conv2D):\n",
        "    \"\"\"Gated Convolutional Class\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(GatedConv2D, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Apply gated convolution\"\"\"\n",
        "\n",
        "        output = super(GatedConv2D, self).call(inputs)\n",
        "        linear = Activation(\"linear\")(inputs)\n",
        "        sigmoid = Activation(\"sigmoid\")(output)\n",
        "\n",
        "        return Multiply()([linear, sigmoid])\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"Return the config of the layer\"\"\"\n",
        "\n",
        "        config = super(GatedConv2D, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def bluche(input_size, d_model, learning_rate):\n",
        "    \"\"\"\n",
        "    Gated Convolucional Recurrent Neural Network by Bluche et al.\n",
        "\n",
        "    Reference:\n",
        "        Bluche, T., Messina, R.:\n",
        "        Gated convolutional recurrent neural networks for multilingual handwriting recognition.\n",
        "        In: Document Analysis and Recognition (ICDAR), 2017\n",
        "        14th IAPR International Conference on, vol. 1, pp. 646–651, 2017.\n",
        "        URL: https://ieeexplore.ieee.org/document/8270042\n",
        "    \"\"\"\n",
        "\n",
        "    input_data = Input(name=\"input\", shape=input_size)\n",
        "    cnn = Reshape((input_size[0] // 2, input_size[1] // 2, input_size[2] * 4))(input_data)\n",
        "\n",
        "    cnn = Conv2D(filters=8, kernel_size=(2,1), strides=(2,1), padding=\"same\", activation=\"relu\")(cnn)\n",
        "  \n",
        "    cnn = Conv2D(filters=16, kernel_size=(2,1), strides=(1,1), padding=\"same\", activation=\"relu\")(cnn)\n",
        "    cnn = GatedConv2D(filters=16, kernel_size=(3,1), strides=(1,1), padding=\"same\")(cnn)\n",
        "    batch = BatchNormalization()(cnn)\n",
        "\n",
        "    cnn = Conv2D(filters=32, kernel_size=(3,1), strides=(1,1), padding=\"same\", activation='relu')(batch)\n",
        "    cnn = GatedConv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\")(cnn)\n",
        "    batch = BatchNormalization()(cnn)\n",
        "\n",
        "    cnn = Conv2D(filters=64, kernel_size=(2,1), strides=(2,2), padding=\"same\", activation=\"relu\")(batch)\n",
        "    cnn = GatedConv2D(filters=64, kernel_size=(2,2), strides=(1,1), padding=\"same\")(cnn)\n",
        "    batch = BatchNormalization()(cnn)\n",
        "\n",
        "    cnn = Conv2D(filters=128, kernel_size=(3,1), strides=(2,2), padding=\"same\", activation=\"relu\")(batch)\n",
        "    cnn = GatedConv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\")(cnn)\n",
        "    batch = BatchNormalization()(cnn)\n",
        "\n",
        "    cnn = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"valid\", activation=\"relu\")(batch)\n",
        "    cnn = MaxPool2D(pool_size=(2,1), padding='same')(cnn)\n",
        "    cnn = MaxPool2D(pool_size=(1, 14))(cnn)\n",
        "    batch = BatchNormalization()(cnn)\n",
        "   \n",
        "    \n",
        "    cnn = MaxPool2D(pool_size=(63,1), padding='valid')(batch)\n",
        "    squeezed = Lambda(lambda x: K.squeeze(x, 1))(cnn)\n",
        "\n",
        "\n",
        "\n",
        "    shape = cnn.get_shape()\n",
        "    blstm = Reshape((shape[1], shape[2] * shape[3]))(batch)\n",
        "\n",
        "    blstm = Bidirectional(LSTM(units=256, return_sequences=True, dropout = 0.5))(blstm)\n",
        "\n",
        "    blstm = Bidirectional(LSTM(units=256, return_sequences=True, dropout = 0.5))(blstm)\n",
        "    output_data = Dense(units=d_model, activation=\"softmax\")(blstm)\n",
        "\n",
        "    if learning_rate is None:\n",
        "        learning_rate = 1e-3\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    return (input_data, output_data, optimizer)\n",
        "\n",
        "def ctc_loss_lambda_func(y_true, y_pred):\n",
        "  \"\"\"Function for computing the CTC loss\"\"\"\n",
        "\n",
        "  if len(y_true.shape) > 1:\n",
        "      y_true = tf.squeeze(y_true)\n",
        "\n",
        "  # y_pred.shape = (batch_size, string_length, alphabet_size_1_hot_encoded)\n",
        "  # output of every model is softmax\n",
        "  # so sum across alphabet_size_1_hot_encoded give 1\n",
        "  #               string_length give string length\n",
        "  input_length = tf.math.reduce_sum(y_pred, axis=-1, keepdims=False)\n",
        "  input_length = tf.math.reduce_sum(input_length, axis=-1, keepdims=True)\n",
        "\n",
        "  # y_true strings are padded with 0\n",
        "  # so sum of non-zero gives number of characters in this string\n",
        "  label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=True, dtype=\"int64\")\n",
        "\n",
        "  loss = K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "  # average loss across all entries in the batch\n",
        "  loss = tf.reduce_mean(loss)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Ecsuv1a1cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loss function and call back\n",
        "from tensorflow.keras.callbacks import CSVLogger, TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "def get_callbacks(checkpoint, monitor=\"val_loss\", verbose=0):\n",
        "        \"\"\"Setup the list of callbacks for the model\"\"\"\n",
        "\n",
        "        callbacks = [\n",
        "            ModelCheckpoint(\n",
        "                filepath=checkpoint,\n",
        "                monitor=monitor,\n",
        "                save_best_only=True,\n",
        "                save_weights_only=True,\n",
        "                verbose=verbose),\n",
        "            EarlyStopping(\n",
        "                monitor=monitor,\n",
        "                min_delta=1e-8,\n",
        "                patience=10,\n",
        "                restore_best_weights=True,\n",
        "                verbose=verbose),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor=monitor,\n",
        "                min_delta=1e-8,\n",
        "                factor=0.2,\n",
        "                patience=5,\n",
        "                verbose=verbose)\n",
        "        ]\n",
        "\n",
        "        return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXxaFQXxZtXQ",
        "colab_type": "code",
        "outputId": "c16c89e7-9063-4ca5-ee94-d18862785175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "#Summary model\n",
        "input_size = (2048, 128, 1)\n",
        "max_text_length = 140\n",
        "\n",
        "outs = bluche(input_size, 140, 1e-3)\n",
        "\n",
        "inputs, outputs, optimizer = outs\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=optimizer, loss=ctc_loss_lambda_func)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2048, 128, 1)]    0         \n",
            "_________________________________________________________________\n",
            "reshape_24 (Reshape)         (None, 1024, 64, 4)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 512, 64, 8)        72        \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 512, 64, 16)       272       \n",
            "_________________________________________________________________\n",
            "gated_conv2d_56 (GatedConv2D (None, 512, 64, 16)       784       \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 512, 64, 16)       64        \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 512, 64, 32)       1568      \n",
            "_________________________________________________________________\n",
            "gated_conv2d_57 (GatedConv2D (None, 512, 64, 32)       9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 512, 64, 32)       128       \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 256, 32, 64)       4160      \n",
            "_________________________________________________________________\n",
            "gated_conv2d_58 (GatedConv2D (None, 256, 32, 64)       16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_69 (Batc (None, 256, 32, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 128, 16, 128)      24704     \n",
            "_________________________________________________________________\n",
            "gated_conv2d_59 (GatedConv2D (None, 128, 16, 128)      147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_70 (Batc (None, 128, 16, 128)      512       \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 126, 14, 256)      295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 63, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 63, 1, 256)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_71 (Batc (None, 63, 1, 256)        1024      \n",
            "_________________________________________________________________\n",
            "reshape_25 (Reshape)         (None, 1, 256)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 1, 512)            1050624   \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 1, 512)            1574912   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1, 140)            71820     \n",
            "=================================================================\n",
            "Total params: 3,199,348\n",
            "Trainable params: 3,198,356\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f6IVSJOaDtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Start train model\n",
        "checkpoint = '/content/drive/My Drive/best.h5'\n",
        "num_steps_train = tf.math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE)   \n",
        "num_steps_test = tf.math.ceil(float(TEST_SAMPLES)/BATCH_SIZE)                        \n",
        "epochs = 30\n",
        "history = model.fit(train_ds,\n",
        "                    steps_per_epoch = num_steps_train,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_ds,\n",
        "                    validation_steps=num_steps_test,\n",
        "                    callbacks=get_callbacks(checkpoint=checkpoint))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}